{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMJy8U+q2ol6enPpRuvm4AY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adithyaac/Captcha-breaker/blob/main/Task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMAGE_SIZE = (150, 50)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE = 0.001\n",
        "MAX_LENGTH = 10\n",
        "HIDDEN_SIZE = 256"
      ],
      "metadata": {
        "id": "xbpvaRaqhMOt"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(easy_dir, hard_dir):\n",
        "\n",
        "    image_paths = []\n",
        "    words = []\n",
        "\n",
        "    for directory in [easy_dir, hard_dir]:\n",
        "        for filename in os.listdir(directory):\n",
        "            if filename.endswith('.png'):\n",
        "\n",
        "                image_paths.append(os.path.join(directory, filename))\n",
        "\n",
        "                word = filename.split('_')[1].split('.')[0]\n",
        "                words.append(word)\n",
        "\n",
        "    return image_paths, words"
      ],
      "metadata": {
        "id": "hiVhuE7JhzP9"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adithyaac/Captcha-breaker.git\n",
        "\n",
        "DATASET_PATH = './Captcha-breaker/captcha_dataset'\n",
        "EASY_DIR = f'{DATASET_PATH}/easy'\n",
        "HARD_DIR = f'{DATASET_PATH}/hard'\n",
        "\n"
      ],
      "metadata": {
        "id": "BcHDVGOjij29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c08f5ff-0ba3-4752-e919-79026c591dae"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Captcha-breaker' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CAPTCHADataset(Dataset):\n",
        "\n",
        "    def __init__(self, image_paths, words, transform=None):\n",
        "\n",
        "        self.image_paths = image_paths\n",
        "        self.words = words\n",
        "        self.transform = transform\n",
        "\n",
        "        all_chars = set(''.join(words))\n",
        "        self.char_to_idx = {char: idx + 1 for idx, char in enumerate(sorted(all_chars))}\n",
        "        self.char_to_idx['<PAD>'] = 0\n",
        "        self.idx_to_char = {idx: char for char, idx in self.char_to_idx.items()}\n",
        "\n",
        "        print(f\"Number of unique characters (including case): {len(all_chars)}\")\n",
        "        print(\"Character set:\", sorted(all_chars))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        word = self.words[idx]\n",
        "        word_indices = [self.char_to_idx[c] for c in word]\n",
        "        word_indices = word_indices + [0] * (MAX_LENGTH - len(word_indices))\n",
        "\n",
        "        return image, torch.tensor(word_indices), len(word)"
      ],
      "metadata": {
        "id": "bFCH-QCdi8v4"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CAPTCHACnnRnn(nn.Module):\n",
        "    def __init__(self, num_chars, hidden_size=HIDDEN_SIZE):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.BatchNorm2d(32),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.BatchNorm2d(64),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.BatchNorm2d(128),\n",
        "        )\n",
        "\n",
        "        self.cnn_output_size = 128 * (IMAGE_SIZE[0] // 8) * (IMAGE_SIZE[1] // 8)\n",
        "\n",
        "        self.reduce_dim = nn.Linear(self.cnn_output_size, hidden_size)\n",
        "\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, num_chars)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.reduce_dim(x)\n",
        "\n",
        "        x = x.unsqueeze(1).repeat(1, MAX_LENGTH, 1)\n",
        "\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        output = self.out(lstm_out)\n",
        "        return output"
      ],
      "metadata": {
        "id": "bcMncLe8nRgU"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    best_val_loss = float('inf')\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, labels, lengths in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            batch_size, seq_len, num_chars = outputs.size()\n",
        "            loss = criterion(outputs.view(-1, num_chars), labels.view(-1))\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(epoch_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct_chars = 0\n",
        "        total_chars = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels, lengths in val_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs.view(-1, outputs.size(-1)),\n",
        "                               labels.view(-1))\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = outputs.max(2)\n",
        "                for pred, label, length in zip(predicted, labels, lengths):\n",
        "                    correct_chars += (pred[:length] == label[:length]).sum().item()\n",
        "                    total_chars += length\n",
        "\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "        accuracy = correct_chars / total_chars * 100\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {epoch_loss:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f}')\n",
        "        print(f'Character Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    return train_losses, val_losses"
      ],
      "metadata": {
        "id": "7qJl3At7nqhw"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "NvwdXnqJntmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83a3524-ce18-4424-8797-2d472f6e0e9a"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths, words = load_dataset(EASY_DIR, HARD_DIR)\n",
        "\n",
        "train_paths, test_paths, train_words, test_words = train_test_split(\n",
        "    image_paths, words, test_size=0.2, random_state=42\n",
        ")\n",
        "train_paths, val_paths, train_words, val_words = train_test_split(\n",
        "    train_paths, train_words, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "JXNMUMk6nzsh"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "NVuEU2uAn9uj"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CAPTCHADataset(train_paths, train_words, transform)\n",
        "val_dataset = CAPTCHADataset(val_paths, val_words, transform)\n",
        "test_dataset = CAPTCHADataset(test_paths, test_words, transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "HY3YJn-VoGNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5243b8b-21b1-466d-d950-3623dd08eda8"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique characters (including case): 46\n",
            "Character set: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n",
            "Number of unique characters (including case): 46\n",
            "Character set: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n",
            "Number of unique characters (including case): 46\n",
            "Character set: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_chars = len(train_dataset.char_to_idx)\n",
        "model = CAPTCHACnnRnn(num_chars).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "history = train_model(model, train_loader, val_loader, criterion,\n",
        "                     optimizer, NUM_EPOCHS, device)"
      ],
      "metadata": {
        "id": "0iEd2-XyoJAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb185ff-3442-4042-cf80-18567e53974c"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30:\n",
            "Train Loss: 2.7632\n",
            "Val Loss: 2.4896\n",
            "Character Accuracy: 22.86%\n",
            "Epoch 2/30:\n",
            "Train Loss: 2.3410\n",
            "Val Loss: 2.2825\n",
            "Character Accuracy: 26.40%\n",
            "Epoch 3/30:\n",
            "Train Loss: 2.1839\n",
            "Val Loss: 2.1562\n",
            "Character Accuracy: 30.08%\n",
            "Epoch 4/30:\n",
            "Train Loss: 2.0605\n",
            "Val Loss: 2.0394\n",
            "Character Accuracy: 32.17%\n",
            "Epoch 5/30:\n",
            "Train Loss: 1.9305\n",
            "Val Loss: 1.9599\n",
            "Character Accuracy: 33.93%\n",
            "Epoch 6/30:\n",
            "Train Loss: 1.7960\n",
            "Val Loss: 1.8565\n",
            "Character Accuracy: 37.29%\n",
            "Epoch 7/30:\n",
            "Train Loss: 1.6460\n",
            "Val Loss: 1.7308\n",
            "Character Accuracy: 41.34%\n",
            "Epoch 8/30:\n",
            "Train Loss: 1.4803\n",
            "Val Loss: 1.5815\n",
            "Character Accuracy: 47.02%\n",
            "Epoch 9/30:\n",
            "Train Loss: 1.2689\n",
            "Val Loss: 1.3823\n",
            "Character Accuracy: 55.13%\n",
            "Epoch 10/30:\n",
            "Train Loss: 1.0096\n",
            "Val Loss: 1.1288\n",
            "Character Accuracy: 64.74%\n",
            "Epoch 11/30:\n",
            "Train Loss: 0.7203\n",
            "Val Loss: 0.9603\n",
            "Character Accuracy: 70.20%\n",
            "Epoch 12/30:\n",
            "Train Loss: 0.4596\n",
            "Val Loss: 0.7425\n",
            "Character Accuracy: 78.67%\n",
            "Epoch 13/30:\n",
            "Train Loss: 0.2608\n",
            "Val Loss: 0.6299\n",
            "Character Accuracy: 82.23%\n",
            "Epoch 14/30:\n",
            "Train Loss: 0.1452\n",
            "Val Loss: 0.5978\n",
            "Character Accuracy: 83.51%\n",
            "Epoch 15/30:\n",
            "Train Loss: 0.0787\n",
            "Val Loss: 0.5732\n",
            "Character Accuracy: 84.84%\n",
            "Epoch 16/30:\n",
            "Train Loss: 0.0646\n",
            "Val Loss: 0.5636\n",
            "Character Accuracy: 85.74%\n",
            "Epoch 17/30:\n",
            "Train Loss: 0.0311\n",
            "Val Loss: 0.5944\n",
            "Character Accuracy: 85.21%\n",
            "Epoch 18/30:\n",
            "Train Loss: 0.1119\n",
            "Val Loss: 0.5791\n",
            "Character Accuracy: 85.60%\n",
            "Epoch 19/30:\n",
            "Train Loss: 0.0371\n",
            "Val Loss: 0.5388\n",
            "Character Accuracy: 86.76%\n",
            "Epoch 20/30:\n",
            "Train Loss: 0.0151\n",
            "Val Loss: 0.5291\n",
            "Character Accuracy: 87.61%\n",
            "Epoch 21/30:\n",
            "Train Loss: 0.0140\n",
            "Val Loss: 0.6030\n",
            "Character Accuracy: 85.94%\n",
            "Epoch 22/30:\n",
            "Train Loss: 0.0484\n",
            "Val Loss: 0.6685\n",
            "Character Accuracy: 84.09%\n",
            "Epoch 23/30:\n",
            "Train Loss: 0.0278\n",
            "Val Loss: 0.5928\n",
            "Character Accuracy: 86.76%\n",
            "Epoch 24/30:\n",
            "Train Loss: 0.0158\n",
            "Val Loss: 0.5683\n",
            "Character Accuracy: 87.61%\n",
            "Epoch 25/30:\n",
            "Train Loss: 0.0083\n",
            "Val Loss: 0.5502\n",
            "Character Accuracy: 88.21%\n",
            "Epoch 26/30:\n",
            "Train Loss: 0.0370\n",
            "Val Loss: 0.6306\n",
            "Character Accuracy: 86.51%\n",
            "Epoch 27/30:\n",
            "Train Loss: 0.0244\n",
            "Val Loss: 0.6020\n",
            "Character Accuracy: 87.11%\n",
            "Epoch 28/30:\n",
            "Train Loss: 0.0111\n",
            "Val Loss: 0.5408\n",
            "Character Accuracy: 88.47%\n",
            "Epoch 29/30:\n",
            "Train Loss: 0.0068\n",
            "Val Loss: 0.5726\n",
            "Character Accuracy: 87.86%\n",
            "Epoch 30/30:\n",
            "Train Loss: 0.0306\n",
            "Val Loss: 0.5909\n",
            "Character Accuracy: 87.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_char_metrics(model, data_loader, device):\n",
        "\n",
        "    correct_chars = 0\n",
        "    total_chars = 0\n",
        "    char_errors = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels, lengths in data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(2)\n",
        "\n",
        "            for pred, label, length in zip(predicted, labels, lengths):\n",
        "                pred_chars = [train_dataset.idx_to_char[idx.item()] for idx in pred[:length]]\n",
        "                true_chars = [train_dataset.idx_to_char[idx.item()] for idx in label[:length]]\n",
        "\n",
        "                correct_chars += sum(p == t for p, t in zip(pred_chars, true_chars))\n",
        "                total_chars += length\n",
        "\n",
        "                if pred_chars != true_chars:\n",
        "                    char_errors.append({\n",
        "                        'predicted': ''.join(pred_chars),\n",
        "                        'actual': ''.join(true_chars)\n",
        "                    })\n",
        "\n",
        "    accuracy = correct_chars / total_chars * 100\n",
        "    return accuracy, char_errors"
      ],
      "metadata": {
        "id": "fkSMB3AQrvjl"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_word_metrics(model, data_loader, device):\n",
        "\n",
        "    correct_words = 0\n",
        "    total_words = 0\n",
        "    word_examples = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels, lengths in data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(2)\n",
        "\n",
        "            for pred, label, length in zip(predicted, labels, lengths):\n",
        "                pred_word = ''.join([train_dataset.idx_to_char[idx.item()]\n",
        "                                   for idx in pred[:length]])\n",
        "                true_word = ''.join([train_dataset.idx_to_char[idx.item()]\n",
        "                                   for idx in label[:length]])\n",
        "\n",
        "                is_correct = pred_word == true_word\n",
        "                if is_correct:\n",
        "                    correct_words += 1\n",
        "\n",
        "                word_examples.append({\n",
        "                    'predicted': pred_word,\n",
        "                    'actual': true_word,\n",
        "                    'correct': is_correct\n",
        "                })\n",
        "                total_words += 1\n",
        "\n",
        "    accuracy = correct_words / total_words * 100\n",
        "    return accuracy, word_examples"
      ],
      "metadata": {
        "id": "ji8ujqRzr5G7"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model_path, test_loader, device):\n",
        "\n",
        "    char_accuracy, char_errors = compute_char_metrics(model, test_loader, device)\n",
        "    word_accuracy, word_examples = compute_word_metrics(model, test_loader, device)\n",
        "\n",
        "    print(f\"Character-level Accuracy: {char_accuracy:.2f}%\")\n",
        "    print(f\"Word-level Accuracy: {word_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "evaluate_model('best_model.pth', test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mANEnMVns6be",
        "outputId": "cd078628-3e50-40bf-a4de-213ee01c5d99"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character-level Accuracy: 87.47%\n",
            "Word-level Accuracy: 68.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_single_image(model, image_path, transform, device):\n",
        "    model.eval()\n",
        "\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted = output.max(2)\n",
        "\n",
        "        pred_word = ''.join([train_dataset.idx_to_char[idx.item()]\n",
        "                            for idx in predicted[0]])\n",
        "\n",
        "        print(f\"Predicted word: {pred_word}\")\n",
        "\n",
        "\n",
        "test_single_image(model, \"0_CHaNCe.png\", transform, device)"
      ],
      "metadata": {
        "id": "Snn4KO9ilSh3",
        "outputId": "cc5fca37-85dc-4bda-fe0f-409f8f1f8c40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted word: CHaNCeeeee\n"
          ]
        }
      ]
    }
  ]
}